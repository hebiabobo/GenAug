{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HbWKisU6So6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "main_path = \"data\"\n",
    "os.chdir(main_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVNmc81hxehU"
   },
   "source": [
    "## Keyword Extraction & POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTNsi2sJgsk7"
   },
   "outputs": [],
   "source": [
    "#!cd \"/content/drive/My Drive/\"\n",
    "#!wget https://nlp.stanford.edu/software/stanford-postagger-2018-10-16.zip\n",
    "#!unzip stanford-postagger-2018-10-16.zip\n",
    "#!mv stanford-postagger-2018-10-16.zip stanford-postagger\n",
    "#!python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "UxzguzN8bTnO",
    "outputId": "f3633333-d9dc-4df5-800b-9f7cd29a2dac"
   },
   "outputs": [],
   "source": [
    "# Import Stanford POS Tagger\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "_path_to_model = 'stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger'\n",
    "_path_to_jar = 'stanford-postagger-2018-10-16/stanford-postagger.jar'\n",
    "st = StanfordPOSTagger(model_filename=_path_to_model, path_to_jar=_path_to_jar)\n",
    "\n",
    "# Install RAKE for keyword extraction\n",
    "!pip3 install python-rake\n",
    "import RAKE\n",
    "Rake = RAKE.Rake(\"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "ADkSah4NJE_V",
    "outputId": "56b5a4af-3c13-404e-883e-517daa77fe63"
   },
   "outputs": [],
   "source": [
    "# Import Stanford POS Tagger\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('tagsets')\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "_path_to_model = 'stanford-postagger-2018-10-16/models/english-bidirectional-distsim.tagger'\n",
    "_path_to_jar = 'stanford-postagger-2018-10-16/stanford-postagger.jar'\n",
    "stanford_tagger = StanfordPOSTagger(model_filename=_path_to_model, path_to_jar=_path_to_jar)\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from nltk.data import load\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0BcstMCy8XF"
   },
   "outputs": [],
   "source": [
    "def extract_keywords_and_POS(prompt):\n",
    "    POS_dict = {}\n",
    "    try:\n",
    "        tagged_prompt = st.tag(prompt.split())\n",
    "    except:\n",
    "        print(\"ERROR PROMPT: \", prompt)\n",
    "        return False\n",
    "    else:\n",
    "        for pair in tagged_prompt:\n",
    "            POS_dict[pair[0]] = pair[1]\n",
    "        keywords_dict = {}\n",
    "        #format: Rake.run(prompt, minCharacters = X, maxWords = Y, minFrequency = Z)\n",
    "        keywords = Rake.run(prompt)\n",
    "        for pair in keywords:\n",
    "            words = pair[0].split()\n",
    "            for word in words:\n",
    "                try:\n",
    "                    keywords_dict[word] = POS_dict[word]\n",
    "                except:\n",
    "                    pass\n",
    "        return keywords_dict\n",
    "\n",
    "#Example:\n",
    "prompt = \"first thing we do , let's fight all the lawyers\"\n",
    "keywords_dict = extract_keywords_and_POS(prompt)\n",
    "print(keywords_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iifenUIKNkv0"
   },
   "source": [
    "## WordNet: Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "31Gb_WOrNm1x",
    "outputId": "5a162122-5379-47df-ee96-fa5238f1f1cd"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_synonyms(word, pos):\n",
    "    synonyms = []\n",
    "    try:\n",
    "        syn_lst = wordnet.synsets(word, pos)\n",
    "        if len(syn_lst) == 0:\n",
    "            syn_lst = wordnet.synsets(word)\n",
    "    except:\n",
    "        try:\n",
    "            syn_lst = wordnet.synsets(word)\n",
    "        except:\n",
    "            return synonyms\n",
    "    for syn in syn_lst:\n",
    "        for l in syn.lemmas():\n",
    "            if l.name().lower() != word:\n",
    "                synonyms.append(l.name().lower())\n",
    "    return list(dict.fromkeys(synonyms))\n",
    "\n",
    "#Example:\n",
    "print(get_synonyms(\"person\", \"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HpVW70jlTTkU",
    "outputId": "816c2a6c-cba6-48a6-ddfa-b2a8660b1072"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "def single_prompt_helper(keywords_lst, keywords_dict, fnc, chosen_nums):\n",
    "    counter = 1\n",
    "    chosen_keywords_lst = []\n",
    "    chosen_replacements_lst = []\n",
    "    for i in range(0,len(keywords_lst)):\n",
    "        if counter <= max(chosen_nums):\n",
    "            keyword = keywords_lst[i]\n",
    "            keyword_pos = keywords_dict[keyword][0].lower()\n",
    "            if keyword_pos == 'j':\n",
    "                keyword_pos = 'a'\n",
    "            candidates = fnc(keyword, keyword_pos)\n",
    "            if len(candidates) != 0:\n",
    "                counter += 1\n",
    "                chosen_keywords_lst.append(keyword)\n",
    "                chosen_replacement = random.choice(candidates)\n",
    "                chosen_replacements_lst.append(chosen_replacement)\n",
    "        else:\n",
    "            return chosen_keywords_lst, chosen_replacements_lst\n",
    "    return chosen_keywords_lst, chosen_replacements_lst\n",
    "\n",
    "\n",
    "def single_prompt_wordnet(prompt, nums_lst):\n",
    "    original_prompt = prompt\n",
    "    synonyms_prompt_lst = []\n",
    "    keywords_dict = extract_keywords_and_POS(prompt)\n",
    "    if keywords_dict == False:\n",
    "        return []\n",
    "    keywords_lst = list(keywords_dict.keys())\n",
    "    num_keywords = len(keywords_lst)\n",
    "    prompt_synonym = original_prompt\n",
    "    chosen_keywords, chosen_synonyms = single_prompt_helper(keywords_lst, keywords_dict, get_synonyms, nums_lst)\n",
    "    counter = 1\n",
    "    for chosen_word, chosen_synonym in zip(chosen_keywords, chosen_synonyms):\n",
    "        prompt_synonym = re.sub(r\"\\b%s\\b\" % chosen_word, chosen_synonym, prompt_synonym)\n",
    "        if counter in nums_lst:\n",
    "            synonyms_prompt_lst.append(re.sub('_',' ',prompt_synonym))\n",
    "        counter += 1\n",
    "    return synonyms_prompt_lst\n",
    "\n",
    "\n",
    "#Example:\n",
    "random.seed(54321)\n",
    "nums_lst = [1,2,3]\n",
    "prompt = \"an immortal being is explaining\"\n",
    "synonyms_lst = single_prompt_wordnet(prompt,nums_lst)\n",
    "print(synonyms_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RmpINVbV6x6"
   },
   "outputs": [],
   "source": [
    "def main_wordnet(input_file, output_file, nums_lst):\n",
    "    synonym_prompt_lst = []\n",
    "    synonym_counter = 0\n",
    "    with open(input_file) as in_f:\n",
    "        input_prompts = in_f.readlines()\n",
    "    counter = 0\n",
    "    for prompt in input_prompts:\n",
    "        synonym_lst = single_prompt_wordnet(prompt.strip('\\n'), nums_lst)\n",
    "        if synonym_lst is not None and len(synonym_lst) > 0:\n",
    "            synonym_counter += 1\n",
    "            synonym_prompt_lst.append('\\t'.join(synonym_lst)+'\\n')\n",
    "        else:\n",
    "            synonym_prompt_lst.append('<blank>\\n')\n",
    "        if counter % 100 == 0:\n",
    "            print(counter)\n",
    "            write_wordnet_prompts(synonym_prompt_lst, output_file)\n",
    "            synonym_prompt_lst = []\n",
    "        counter += 1\n",
    "    write_wordnet_prompts(synonym_prompt_lst, output_file)\n",
    "    print(\"Final synonym lines: \", synonym_counter)\n",
    "    return synonym_prompt_lst\n",
    "\n",
    "\n",
    "def write_wordnet_prompts(synonym_lst, output_file):\n",
    "    f = open(output_file, 'a')\n",
    "    print(\"Writing output prompts to file...\")\n",
    "    f.writelines(synonym_lst)\n",
    "    f.close()\n",
    "    print(\"Output prompts written to file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "F4xrUzfjChu8",
    "outputId": "41b5baf0-ee89-4c06-848a-4e7919b28c72"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "random.seed(54321)\n",
    "nums_lst = [1,2,3]\n",
    "input_file = 'yelp_train.txt'\n",
    "output_file = 'yelp_train_synonyms.txt'\n",
    "\n",
    "start = time.time()\n",
    "synonyms_lst = main_wordnet(input_file, output_file, nums_lst)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PROSEAM_WordNet_Synonyms (Random Seed).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
