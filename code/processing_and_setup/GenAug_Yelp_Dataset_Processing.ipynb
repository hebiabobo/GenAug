{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3W4JOpp1ZG1M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "main_path = \"data\"\n",
    "os.chdir(main_path)\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_WXqDv-uQlGk"
   },
   "source": [
    "## Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4DV-PESGQmd9",
    "outputId": "3f628a8c-47a5-4213-91e6-e31a9c7fc883"
   },
   "outputs": [],
   "source": [
    "# Install RAKE for keyword extraction\n",
    "!pip3 install python-rake\n",
    "import RAKE\n",
    "Rake = RAKE.Rake(\"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pgJ6X5jGQwXD",
    "outputId": "2e0e59dd-754d-4c85-c15f-31df46374b67"
   },
   "outputs": [],
   "source": [
    "def extract_keywords_len(prompt):\n",
    "    #format: Rake.run(prompt, minCharacters = X, maxWords = Y, minFrequency = Z)\n",
    "    keywords = Rake.run(prompt)\n",
    "    length = len(keywords)\n",
    "    return length\n",
    "\n",
    "#Example:\n",
    "prompt = \"first thing we do , let's fight all the lawyers\"\n",
    "keywords_len = extract_keywords_len(prompt)\n",
    "print(keywords_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gS4C6MOPtfl"
   },
   "source": [
    "## Yelp Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pFfl5Epo_5T"
   },
   "outputs": [],
   "source": [
    "import io, json, os, collections, pprint, time\n",
    "import re\n",
    "from string import punctuation\n",
    "import unicodedata\n",
    "import random\n",
    "\n",
    "\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def process_text(s):\n",
    "    s = unicodeToAscii(s.lower().strip()) \n",
    "    s = re.sub('\\!+', '!', s)\n",
    "    s = re.sub('\\,+', ',', s)\n",
    "    s = re.sub('\\?+', '?', s)\n",
    "    s = re.sub('\\.+', '.', s)\n",
    "    s = re.sub('\\$+', '$', s)        \n",
    "    s = re.sub(\"[^a-zA-Z0-9$.!?,'']+\", ' ', s)\n",
    "    for p in punctuation:\n",
    "        if p != \"'\":\n",
    "            s = s.replace(p, \" \" + p + \" \")       \n",
    "    s = re.sub(' +', ' ', s)\n",
    "    s = s.strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8p0DquapEZy"
   },
   "outputs": [],
   "source": [
    "def filter_reviews(path):\n",
    "    review_list = []\n",
    "    one_star_list = []\n",
    "    two_star_list = []\n",
    "    three_star_list = []\n",
    "    four_star_list = []\n",
    "    five_star_list = []\n",
    "    review_list_2 = []\n",
    "    one_star_list_2 = []\n",
    "    two_star_list_2 = []\n",
    "    three_star_list_2 = []\n",
    "    four_star_list_2 = []\n",
    "    five_star_list_2 = []\n",
    "    total_count = 0\n",
    "    one_star_count = 0\n",
    "    two_star_count = 0\n",
    "    three_star_count = 0\n",
    "    four_star_count = 0\n",
    "    five_star_count = 0\n",
    "    f = io.open(path, encoding = 'utf-8')\n",
    "    counter = 0\n",
    "    print(\"Currently reading lines from file ...\")\n",
    "    for l in f:\n",
    "        if counter % 100000 == 0:\n",
    "            print(\"Read in {%d} lines\" % counter)\n",
    "        jline = json.loads(l)\n",
    "        if jline['text'] != '' and isEnglish(jline['text']) \\\n",
    "            and 'http' not in jline['text'].lower() and 'www' not in jline['text'].lower():\n",
    "            clean_line = re.sub('\\s+', ' ', jline['text']).strip()\n",
    "            clean_line_final = process_text(clean_line)\n",
    "            total_count += 1\n",
    "            if jline['stars'] == 1.0:\n",
    "                one_star_count += 1\n",
    "            elif jline['stars'] == 2.0:\n",
    "                two_star_count += 1\n",
    "            elif jline['stars'] == 3.0:\n",
    "                three_star_count += 1\n",
    "            elif jline['stars'] == 4.0:\n",
    "                four_star_count += 1\n",
    "            elif jline['stars'] == 5.0:\n",
    "                five_star_count += 1\n",
    "            if len(clean_line_final.split()) <= 40:\n",
    "                num_keywords = extract_keywords_len(clean_line_final)\n",
    "                if num_keywords >= 4:\n",
    "                    if jline['stars'] == 1.0:\n",
    "                        one_star_list.append(clean_line_final + '\\t' + '0' + '\\n')\n",
    "                    elif jline['stars'] == 2.0:\n",
    "                        two_star_list.append(clean_line_final + '\\t' + '0.25' + '\\n')\n",
    "                    elif jline['stars'] == 3.0:\n",
    "                        three_star_list.append(clean_line_final + '\\t' + '0.5' + '\\n')\n",
    "                    elif jline['stars'] == 4.0:\n",
    "                        four_star_list.append(clean_line_final + '\\t' + '0.75' + '\\n')\n",
    "                    elif jline['stars'] == 5.0:\n",
    "                        five_star_list.append(clean_line_final + '\\t' + '1' + '\\n')\n",
    "                    review_list.append(clean_line_final + '\\t' + str((jline['stars']-1)/4) + '\\n')\n",
    "                else:\n",
    "                    if jline['stars'] == 1.0:\n",
    "                        one_star_list_2.append(clean_line_final + '\\t' + '0' + '\\n')\n",
    "                    elif jline['stars'] == 2.0:\n",
    "                        two_star_list_2.append(clean_line_final + '\\t' + '0.25' + '\\n')\n",
    "                    elif jline['stars'] == 3.0:\n",
    "                        three_star_list_2.append(clean_line_final + '\\t' + '0.5' + '\\n')\n",
    "                    elif jline['stars'] == 4.0:\n",
    "                        four_star_list_2.append(clean_line_final + '\\t' + '0.75' + '\\n')\n",
    "                    elif jline['stars'] == 5.0:\n",
    "                        five_star_list_2.append(clean_line_final + '\\t' + '1' + '\\n')\n",
    "                    review_list_2.append(clean_line_final + '\\t' + str((jline['stars']-1)/4) + '\\n')\n",
    "        counter += 1\n",
    "    return review_list, one_star_list, two_star_list, three_star_list, four_star_list, five_star_list, review_list_2, one_star_list_2, two_star_list_2, three_star_list_2, four_star_list_2, five_star_list_2, one_star_count, two_star_count, three_star_count, four_star_count, five_star_count, total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDn7bTJapJtp"
   },
   "outputs": [],
   "source": [
    "def write_lines(lst, output_path_1, output_path_2):\n",
    "    f1 = io.open(output_path_1, \"w\", encoding = 'utf-8')\n",
    "    print(\"Currently writing lines to file1 ...\")\n",
    "    f1.writelines(lst)\n",
    "    f1.close()\n",
    "    print(\"Lines successfully written to file1!\")\n",
    "\n",
    "    f2 = io.open(output_path_2, \"w\", encoding = 'utf-8')\n",
    "    print(\"Currently writing lines to file2 ...\")\n",
    "    for line in lst:\n",
    "        new_line = line.split('\\t')[0] + '\\n'\n",
    "        f2.write(new_line)\n",
    "    f2.close()\n",
    "    print(\"Lines successfully written to file2!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iro0qdVfTC09"
   },
   "source": [
    "# Execution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ujxwjzMpXBx"
   },
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "input_path = os.path.join(main_path, 'review.json') #this is the original Yelp Reviews dataset file containing all reviews\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "review_list, one_star_list, two_star_list, three_star_list, four_star_list, five_star_list, review_list_2, one_star_list_2, two_star_list_2, three_star_list_2, four_star_list_2, five_star_list_2, one_star_count, two_star_count, three_star_count, four_star_count, five_star_count, total_count = filter_reviews(input_path)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikRUgx-FHzF0"
   },
   "outputs": [],
   "source": [
    "print(\"Number of total reviews: \", total_count)\n",
    "print(\"Number of one star reviews: \", one_star_count)\n",
    "print(\"Number of two star reviews: \", two_star_count)\n",
    "print(\"Number of three star reviews: \", three_star_count)\n",
    "print(\"Number of four star reviews: \", four_star_count)\n",
    "print(\"Number of five star reviews: \", five_star_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBwQxjp2UZSj"
   },
   "source": [
    "## For Yelp Low-Resource (YLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "-sFfdJn6Huzc",
    "outputId": "6e9bf97c-2123-4621-8a79-9dbbcd4537ee"
   },
   "outputs": [],
   "source": [
    "total_reviews = len(review_list)\n",
    "print(\"Number of total reviews: \", total_reviews)\n",
    "\n",
    "one_star_reviews = len(one_star_list)\n",
    "print(\"Number of one star reviews: \", one_star_reviews)\n",
    "\n",
    "two_star_reviews = len(two_star_list)\n",
    "print(\"Number of two star reviews: \", two_star_reviews)\n",
    "\n",
    "three_star_reviews = len(three_star_list)\n",
    "print(\"Number of three star reviews: \", three_star_reviews)\n",
    "\n",
    "four_star_reviews = len(four_star_list)\n",
    "print(\"Number of four star reviews: \", four_star_reviews)\n",
    "\n",
    "five_star_reviews = len(five_star_list)\n",
    "print(\"Number of five star reviews: \", five_star_reviews)\n",
    "\n",
    "random.shuffle(one_star_list)\n",
    "random.shuffle(two_star_list)\n",
    "random.shuffle(three_star_list)\n",
    "random.shuffle(four_star_list)\n",
    "random.shuffle(five_star_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sE1x9JIt9nNH",
    "outputId": "3e023562-fa2b-4e4d-decf-591592a1d68f"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "random.seed(12345)\n",
    "\n",
    "train_one_star = one_star_list[:math.ceil(50000*(one_star_count/total_count))]\n",
    "train_two_star = two_star_list[:math.ceil(50000*(two_star_count/total_count))]\n",
    "train_three_star = three_star_list[:math.ceil(50000*(three_star_count/total_count))]\n",
    "train_four_star = four_star_list[:math.ceil(50000*(four_star_count/total_count))]\n",
    "train_five_star = five_star_list[:math.ceil(50000*(five_star_count/total_count))]\n",
    "\n",
    "valid_one_star = one_star_list[math.ceil(50000*(one_star_count/total_count)):math.ceil(50000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count))]\n",
    "valid_two_star = two_star_list[math.ceil(50000*(two_star_count/total_count)):math.ceil(50000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count))]\n",
    "valid_three_star = three_star_list[math.ceil(50000*(three_star_count/total_count)):math.ceil(50000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count))]\n",
    "valid_four_star = four_star_list[math.ceil(50000*(four_star_count/total_count)):math.ceil(50000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count))]\n",
    "valid_five_star = five_star_list[math.ceil(50000*(five_star_count/total_count)):math.ceil(50000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count))]\n",
    "\n",
    "valid_sent_one_star = one_star_list[math.ceil(50000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count)):math.ceil(50000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count))]\n",
    "valid_sent_two_star = two_star_list[math.ceil(50000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count)):math.ceil(50000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count))]\n",
    "valid_sent_three_star = three_star_list[math.ceil(50000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count)):math.ceil(50000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count))]\n",
    "valid_sent_four_star = four_star_list[math.ceil(50000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count)):math.ceil(50000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count))]\n",
    "valid_sent_five_star = five_star_list[math.ceil(50000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count)):math.ceil(50000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count))]\n",
    "\n",
    "test_one_star = one_star_list[math.ceil(50000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count)):math.ceil(50000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count))+math.ceil(5000*(one_star_count/total_count))]\n",
    "test_two_star = two_star_list[math.ceil(50000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count)):math.ceil(50000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count))+math.ceil(5000*(two_star_count/total_count))]\n",
    "test_three_star = three_star_list[math.ceil(50000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count)):math.ceil(50000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count))+math.ceil(5000*(three_star_count/total_count))]\n",
    "test_four_star = four_star_list[math.ceil(50000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count)):math.ceil(50000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count))+math.ceil(5000*(four_star_count/total_count))]\n",
    "test_five_star = five_star_list[math.ceil(50000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count)):math.ceil(50000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count))+math.ceil(5000*(five_star_count/total_count))]\n",
    "\n",
    "end_index_one = math.ceil(50000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count))+math.ceil(15000*(one_star_count/total_count))+math.ceil(5000*(one_star_count/total_count))\n",
    "end_index_two = math.ceil(50000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count))+math.ceil(15000*(two_star_count/total_count))+math.ceil(5000*(two_star_count/total_count))\n",
    "end_index_three = math.ceil(50000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count))+math.ceil(15000*(three_star_count/total_count))+math.ceil(5000*(three_star_count/total_count))\n",
    "end_index_four = math.ceil(50000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count))+math.ceil(15000*(four_star_count/total_count))+math.ceil(5000*(four_star_count/total_count))\n",
    "end_index_five = math.ceil(50000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count))+math.ceil(15000*(five_star_count/total_count))+math.ceil(5000*(five_star_count/total_count))\n",
    "\n",
    "final_train_reviews = train_one_star + train_two_star + train_three_star + train_four_star + train_five_star\n",
    "final_valid_reviews = valid_one_star + valid_two_star + valid_three_star + valid_four_star + valid_five_star\n",
    "final_valid_sent_reviews = valid_sent_one_star + valid_sent_two_star + valid_sent_three_star + valid_sent_four_star + valid_sent_five_star\n",
    "final_test_reviews = test_one_star + test_two_star + test_three_star + test_four_star + test_five_star\n",
    "\n",
    "random.shuffle(final_train_reviews)\n",
    "random.shuffle(final_valid_reviews)\n",
    "random.shuffle(final_valid_sent_reviews)\n",
    "random.shuffle(final_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "07-Dw6SL-evH",
    "outputId": "c8bf42ab-39e2-4dc5-bbd0-e3fa9020c13b"
   },
   "outputs": [],
   "source": [
    "final_train_reviews = final_train_reviews[:50000]\n",
    "final_valid_reviews = final_valid_reviews[:15000]\n",
    "final_valid_sent_reviews = final_valid_sent_reviews[:15000]\n",
    "final_test_reviews = final_test_reviews[:5000]\n",
    "\n",
    "print(len(final_train_reviews))\n",
    "print(len(final_valid_reviews))\n",
    "print(len(final_valid_sent_reviews))\n",
    "print(len(final_test_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "2OeO2uQ_wcGT",
    "outputId": "e9afbca2-b603-4d68-87ac-b8c70c30679f"
   },
   "outputs": [],
   "source": [
    "#files with stars and \"yelp_val_sent\" are for finetuning the BERT sentiment regressor\n",
    "\n",
    "train_path_1 = os.path.join(main_path, 'yelp_train_stars.txt')\n",
    "train_path_2 = os.path.join(main_path, 'yelp_train.txt')\n",
    "valid_path_1 = os.path.join(main_path, 'yelp_val_stars.txt')\n",
    "valid_path_2 = os.path.join(main_path, 'yelp_val.txt')\n",
    "test_path_1 = os.path.join(main_path, 'yelp_test_stars.txt')\n",
    "test_path_2 = os.path.join(main_path, 'yelp_test.txt')\n",
    "valid_sent_path_1 = os.path.join(main_path, 'yelp_val_sent_stars.txt')\n",
    "valid_sent_path_2 = os.path.join(main_path, 'yelp_val_sent.txt')\n",
    "\n",
    "write_lines(final_train_reviews, train_path_1, train_path_2)\n",
    "write_lines(final_valid_reviews, valid_path_1, valid_path_2)\n",
    "write_lines(final_test_reviews, test_path_1, test_path_2)\n",
    "write_lines(final_valid_sent_reviews, valid_sent_path_1, valid_sent_path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8Q6xutri1zm"
   },
   "source": [
    "## For Finetuning GPT-2 for Perplexity/SLOR Evaluation (2 million reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wEFLjo5jAmZ"
   },
   "outputs": [],
   "source": [
    "def filter_reviews_full(path):\n",
    "    review_list = []\n",
    "    f = io.open(path, encoding = 'utf-8')\n",
    "    counter = 0\n",
    "    print(\"Currently reading lines from file ...\")\n",
    "    for l in f:\n",
    "        if counter % 100000 == 0:\n",
    "            print(\"Read in {%d} lines\" % counter)\n",
    "        jline = json.loads(l)\n",
    "        if jline['text'] != '' and isEnglish(jline['text']) \\\n",
    "            and 'http' not in jline['text'].lower() and 'www' not in jline['text'].lower():\n",
    "            clean_line = re.sub('\\s+', ' ', jline['text']).strip()\n",
    "            clean_line_final = process_text(clean_line)\n",
    "            if len(clean_line_final.strip()) != 0:\n",
    "                review_list.append(clean_line_final + '\\t' + str((jline['stars']-1)/4))\n",
    "        counter += 1\n",
    "    print(\"Length of review_list: \", len(review_list))\n",
    "    return review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSyHnZnTjGmk"
   },
   "outputs": [],
   "source": [
    "def write_lines_full(lst, output_path_1, output_path_2):\n",
    "    f1 = io.open(output_path_1, \"w\", encoding = 'utf-8')\n",
    "    print(\"Currently writing lines to file1 ...\")\n",
    "    f1.write('\\n'.join(lst))\n",
    "    f1.close()\n",
    "    print(\"Lines successfully written to file1!\")\n",
    "\n",
    "    f2 = io.open(output_path_2, \"w\", encoding = 'utf-8')\n",
    "    print(\"Currently writing lines to file2 ...\")\n",
    "    for line in lst:\n",
    "        new_line = line.split('\\t')[0] + '\\n'\n",
    "        f2.write(new_line)\n",
    "    f2.close()\n",
    "    print(\"Lines successfully written to file2!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EUQzkBQujMTx",
    "outputId": "2bc19514-a90f-4678-be57-1005127b54f3"
   },
   "outputs": [],
   "source": [
    "input_path = 'review.json' #original Yelp Reviews dataset (over 6 million reviews)\n",
    "output_path_train_stars = 'yelp_train_full_stars.txt'\n",
    "output_path_train = 'yelp_train_full.txt'\n",
    "output_path_val_stars = 'yelp_val_full_stars.txt'\n",
    "output_path_val = 'yelp_val_full.txt'\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "#review_list = filter_reviews_full(input_path)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "BKy3bUF9lplC",
    "outputId": "9fd4c419-feaa-457f-81a1-3b4a2cc06a16"
   },
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "random.shuffle(review_list)\n",
    "train_lst = review_list[:2000000]\n",
    "val_lst = review_list[2000000:2500000]\n",
    "#write_lines_full(train_lst, output_path_train_stars, output_path_train)\n",
    "#write_lines_full(val_lst, output_path_val_stars, output_path_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VuMYSkDvSHju"
   },
   "source": [
    "## Get Unigram Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This will be used for SLOR normalization (on yelp_full (2 million reviews)) and rare_words metric (on YLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNCJ62sPYZn2"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4bD80ycSLA0"
   },
   "outputs": [],
   "source": [
    "import io, json, os, collections, pprint, time\n",
    "import re\n",
    "from string import punctuation\n",
    "import unicodedata\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "lm_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "\n",
    "def get_unigrams_test(lst):\n",
    "    unigrams_dict = defaultdict(lambda: [0,0])\n",
    "    counter = 0\n",
    "    for l in lst:\n",
    "        tokenized_line = lm_tokenizer.tokenize(l)\n",
    "        print(\"tokenized_line: \", tokenized_line)\n",
    "        for token in tokenized_line:\n",
    "            unigrams_dict[token][0] += 1\n",
    "        counter += 1\n",
    "    print(\"Length of unigrams_dict: \", len(unigrams_dict))\n",
    "    total_freq = 0\n",
    "    for k,v in unigrams_dict.items():\n",
    "        total_freq += v[0]\n",
    "    print(\"Total_freq: \", total_freq)\n",
    "    for k,v in unigrams_dict.items():\n",
    "        v[1] = v[0]/total_freq\n",
    "    unigrams_dict = {k: v for k, v in sorted(unigrams_dict.items(), key=lambda item: item[1][1], reverse=True)}\n",
    "    return unigrams_dict\n",
    "\n",
    "\n",
    "def get_unigrams(path):\n",
    "    unigrams_dict = defaultdict(lambda: [0,0])\n",
    "    f = io.open(path, encoding = 'utf-8')\n",
    "    counter = 0\n",
    "    print(\"Currently getting unigrams from file ...\")\n",
    "    for l in f:\n",
    "        if counter % 100000 == 0:\n",
    "            print(\"Read in {%d} lines\" % counter)\n",
    "        tokenized_line = lm_tokenizer.tokenize(l)\n",
    "        for token in tokenized_line:\n",
    "            unigrams_dict[token][0] += 1\n",
    "        counter += 1\n",
    "    print(\"Length of unigrams_dict: \", len(unigrams_dict))\n",
    "    total_freq = 0\n",
    "    for k,v in unigrams_dict.items():\n",
    "        total_freq += v[0]\n",
    "    print(\"Total_freq: \", total_freq)\n",
    "    for k,v in unigrams_dict.items():\n",
    "        v[1] = v[0]/total_freq\n",
    "    unigrams_dict = {k: v for k, v in sorted(unigrams_dict.items(), key=lambda item: item[1][1], reverse=True)}\n",
    "    return unigrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgHHGs9tSdwK"
   },
   "outputs": [],
   "source": [
    "def write_unigrams(unigrams_dict, output_path):\n",
    "    f = io.open(output_path, \"w\", encoding = 'utf-8')\n",
    "    print(\"Currently writing unigrams to file ...\")\n",
    "    for key, value in unigrams_dict.items():\n",
    "        f.write(key + '\\t' + str(value[0]) + '\\t' + str(value[1]) + '\\n')\n",
    "    f.close()\n",
    "    print(\"Unigrams successfully written to file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "00DLIv0oXBYS",
    "outputId": "095c87da-1dd8-47f5-b140-45c0bbf8713d"
   },
   "outputs": [],
   "source": [
    "#examples\n",
    "lst = ['hello i am steven',\n",
    "       'hello who are hello?',\n",
    "       'wow this this this']\n",
    "unigrams_dict = get_unigrams_test(lst)\n",
    "print(unigrams_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "kd3KNnmgSe_r",
    "outputId": "ab093739-7c83-4ab6-ef49-01f60eec8464"
   },
   "outputs": [],
   "source": [
    "input_path = 'yelp_train_full.txt'\n",
    "output_path = 'yelp_train_full_unigrams.txt'\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "#unigrams_dict = get_unigrams(input_path)\n",
    "#write_unigrams(unigrams_dict, output_path)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PROSEAM_Yelp_Dataset (NEW).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
